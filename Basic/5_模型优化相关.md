# 模型优化相关

------------------

## `Learning Rate`的选择依赖于选择的优化器

&emsp; 对于`Adam Optimizer`，我们通常选择初始学习率为`lr = 3e-4`，且`Adam Optimizer`已经内置了自动进行学习率的衰减更新，不需要人为更新。

-----------------

## **批标准化**`Batch Normalization`的使用

[参考链接：知乎：什么是批标准化 (Batch Normalization)](https://zhuanlan.zhihu.com/p/24810318)
